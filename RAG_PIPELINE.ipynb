{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-04T10:27:46.664230Z",
     "start_time": "2025-07-04T10:27:46.652579Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:27:46.726185Z",
     "start_time": "2025-07-04T10:27:46.719983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ[\"HF_TOKEN\"]=os.getenv('HF_TOKEN')\n",
    "os.environ[\"PINECONE_API_KEY\"]=os.getenv(\"PINECONE_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"rag-pdf-project\"\n"
   ],
   "id": "219e5d379bec6bfb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:27:49.290896Z",
     "start_time": "2025-07-04T10:27:46.787422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders.parsers import RapidOCRBlobParser\n",
    "\n",
    "\n",
    "file_path=\"./data/sample.pdf\"\n",
    "loader=PyMuPDFLoader(\n",
    "    file_path,\n",
    "    mode=\"page\",\n",
    "    images_inner_format=\"markdown-img\",\n",
    "    images_parser=RapidOCRBlobParser(),\n",
    "    #extract_tables=\"markdown\"      --- u can use this when your pdf contains real tables\n",
    ")\n",
    "\n",
    "\n",
    "docs=loader.load()"
   ],
   "id": "674cc06863ae11fe",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:27:49.329373Z",
     "start_time": "2025-07-04T10:27:49.314026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pprint\n",
    "pprint.pp(docs[215].page_content)"
   ],
   "id": "4ea270216f080a95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Notes to the Group Financial Statements continued\\n'\n",
      " '33. Group companies\\n'\n",
      " 'In accordance with Section 409 of the Companies Act 2006, a full list of '\n",
      " 'entities in which the Group has an interest of greater than or equal \\n'\n",
      " 'to 20%, the registered office and effective percentage of equity owned as at '\n",
      " '31 December 2023 are disclosed below. Unless otherwise stated, \\n'\n",
      " 'the ownership interest disclosed comprises either ordinary shares, '\n",
      " 'certificated or un-certificated membership interests which are indirectly \\n'\n",
      " 'held by InterContinental Hotels Group PLC.\\n'\n",
      " 'Fully owned subsidiaries\\n'\n",
      " '10000 Champion Acquisition LLC (k)\\n'\n",
      " '24th Street Operator Sub, LLC (k)\\n'\n",
      " '2250 Blake Street Hotel, LLC (k)\\n'\n",
      " '36th Street IHG Sub, LLC (k)\\n'\n",
      " '426 Main Ave, LLC. (k)\\n'\n",
      " '46 Nevins Street Associates, LLC (k)\\n'\n",
      " 'Alpha Kimball Hotel, LLC (k)\\n'\n",
      " 'Asia Pacific Holdings Limited (n)\\n'\n",
      " 'Barclay Operating Corp. (k)\\n'\n",
      " 'BHMC Canada Inc. (o)\\n'\n",
      " 'BHR Holdings B.V. (p)\\n'\n",
      " 'BHR Pacific Holdings, Inc. (k)\\n'\n",
      " 'BHTC Canada Inc. (o)\\n'\n",
      " 'Blythswood Square Glasgow Hotel OpCo Limited (n)\\n'\n",
      " 'BOC Barclay Sub LLC (k)\\n'\n",
      " 'Bristol Oakbrook Tenant Company (k)\\n'\n",
      " 'Cambridge Lodging LLC (k)\\n'\n",
      " 'Capital Lodging LLC (k)\\n'\n",
      " 'CECNY Land Holdings LLC (k)\\n'\n",
      " 'CF Irving Owner, LLC (k)\\n'\n",
      " 'CF McKinney Owner, LLC (k)\\n'\n",
      " 'Compañia Inter-Continental De Hoteles \\n'\n",
      " 'El Salvador SA (n)\\n'\n",
      " 'Crowne Plaza, LLC (k)\\n'\n",
      " 'Cumberland Akers Hotel, LLC (k)\\n'\n",
      " 'Dunwoody Operations, LLC (k)\\n'\n",
      " 'Edinburgh George Street Hotel OpCo Limited (n)\\n'\n",
      " 'EVEN Real Estate Holding LLC (k)\\n'\n",
      " 'General Innkeeping Acceptance Corporation (b) (k)\\n'\n",
      " 'Grand Central Glasgow Hotel OpCo Limited (n)\\n'\n",
      " 'Guangzhou SC Hotels Services Ltd. (t)\\n'\n",
      " 'Hawthorne Land Holdings LLC (k)\\n'\n",
      " 'HC International Holdings, Inc. (k)\\n'\n",
      " 'HH France Holdings SAS (x)\\n'\n",
      " 'HH Hotels (EMEA) B.V. (p)\\n'\n",
      " 'HH Hotels (Romania) SRL (y)\\n'\n",
      " 'HIM (Aruba) NV (z)\\n'\n",
      " 'Hoft Properties LLC (k)\\n'\n",
      " 'Holiday Hospitality Franchising, LLC (k)\\n'\n",
      " 'Holiday Inn Mexicana S.A. (ab)\\n'\n",
      " 'Holiday Inns (China) Limited (ac)\\n'\n",
      " 'Holiday Inns (Courtalin) Holding SAS (x)\\n'\n",
      " 'Holiday Inns (Courtalin) SAS (x)\\n'\n",
      " 'Holiday Inns (Germany), LLC (k)\\n'\n",
      " 'Holiday Inns (Jamaica), Inc. (k)\\n'\n",
      " 'Holiday Inns (Middle East) Limited (ac)\\n'\n",
      " 'Holiday Inns (Philippines), Inc. (k)\\n'\n",
      " 'Holiday Inns (Saudi Arabia), Inc. (k)\\n'\n",
      " 'Holiday Inns (Thailand) Limited (ac)\\n'\n",
      " 'Holiday Inns (U.K.), Inc. (k)\\n'\n",
      " 'Holiday Inns Crowne Plaza (Hong Kong), Inc. (k)\\n'\n",
      " 'Holiday Inns Holdings (Australia) Pty Limited (aa)\\n'\n",
      " 'Holiday Inns, Inc. (k)\\n'\n",
      " 'Holiday Inns Investment (Nepal) Limited (ac)\\n'\n",
      " 'Holiday Inns of Belgium N.V. (ad)\\n'\n",
      " 'Holiday Pacific Equity Corporation (k)\\n'\n",
      " 'Holiday Pacific Limited Liability Company (k)\\n'\n",
      " 'Holiday Pacific Partners Limited Partnership (k)\\n'\n",
      " 'Hotel InterContinental London (Holdings) Limited (n)\\n'\n",
      " 'Hotel Inter-Continental London Limited (n)\\n'\n",
      " 'Hoteles Y Turismo HIH SRL (n)\\n'\n",
      " 'IC Hotelbetriebsführungs GmbH (ae)\\n'\n",
      " 'IC Hotels Management (Portugal) Unipessoal, \\n'\n",
      " 'Lda (af)\\n'\n",
      " 'IC International Hotels Limited Liability \\n'\n",
      " 'Company (ag)\\n'\n",
      " 'IHC Arabia for Management, LLC (u)\\n'\n",
      " 'IHC Buckhead, LLC (k)\\n'\n",
      " 'IHC Hopkins (Holdings) Corp. (k)\\n'\n",
      " 'IHC Hotel Limited (n)\\n'\n",
      " 'IHC Inter-Continental (Holdings) Corp. (k)\\n'\n",
      " 'IHC London (Holdings) (n)\\n'\n",
      " 'IHC May Fair Hotel Limited (n)\\n'\n",
      " 'IHC M-H (Holdings) Corp. (k)\\n'\n",
      " 'IHC Overseas (U.K.) Limited (n)\\n'\n",
      " 'IHC United States (Holdings) Corp. (b) (k)\\n'\n",
      " 'IHC Willard (Holdings) Corp. (k)\\n'\n",
      " 'IHG 24th Street JV LLC (k)\\n'\n",
      " 'IHG (Marseille) SAS (x)\\n'\n",
      " 'IHG (Myanmar) Limited (ah)\\n'\n",
      " 'IHG (Thailand) Limited (bu)\\n'\n",
      " 'IHG Amsterdam Management BV (p)\\n'\n",
      " 'IHG Bangkok Ltd. (v)\\n'\n",
      " 'IHG Brasil Administracao de Hoteis e Servicos \\n'\n",
      " 'Ltda (ak)\\n'\n",
      " 'IHG Capital Lending LLC (k)\\n'\n",
      " 'IHG Commissions Services SRL (co)\\n'\n",
      " 'IHG de Argentina SA (al)\\n'\n",
      " 'IHG ECS (Barbados) SRL (co)\\n'\n",
      " 'IHG Finance LLC- Incorporated 19/06/2023 (k)\\n'\n",
      " 'IHG Franchising Brasil Ltda. (bd)\\n'\n",
      " 'IHG Franchising DR Corporation (k)\\n'\n",
      " 'IHG Franchising, LLC (k)\\n'\n",
      " 'IHG Honduras S. de R.L. (cr)\\n'\n",
      " 'IHG Hotels (New Zealand) Limited (an)\\n'\n",
      " 'IHG Hotels Limited (n)\\n'\n",
      " 'IHG Hotels Management (Australia) Pty \\n'\n",
      " 'Limited (b) (aa)\\n'\n",
      " 'IHG Hotels Nigeria Limited (ao)\\n'\n",
      " 'IHG Hotels South Africa (Pty) Limited (ap)\\n'\n",
      " 'IHG International Partnership (n)\\n'\n",
      " 'IHG Istanbul Otel Yönetim Limited Sirketi (bx)\\n'\n",
      " 'IHG Japan (Management), LLC (ar)\\n'\n",
      " 'IHG Japan (Osaka), LLC (ar)\\n'\n",
      " 'IHG Management (Maryland), LLC (k)\\n'\n",
      " 'IHG Management (Netherlands) B.V. (p)\\n'\n",
      " 'IHG Management d.o.o. Beograd (cc) \\n'\n",
      " 'IHG Management MD Barclay Sub, LLC (k)\\n'\n",
      " 'IHG Management SL d.o.o. (bo)\\n'\n",
      " 'IHG Mexico Operaciones SA de CV (ab)\\n'\n",
      " 'IHG Middle East Management Consultancies LLC (br)\\n'\n",
      " 'IHG Peru SRL (cf)\\n'\n",
      " 'IHG PS Nominees Limited (n)\\n'\n",
      " 'IHG Sermex SA de CV (ab)\\n'\n",
      " 'IHG Systems Pty Ltd. (b) (aa)\\n'\n",
      " 'IHG Szalloda Budapest Szolgaltato Kft. (at)\\n'\n",
      " 'IHG Technology Solutions, LLC (k)\\n'\n",
      " 'InterContinental Berlin Service Company GmbH (au)\\n'\n",
      " 'InterContinental (PB) 1 (n)\\n'\n",
      " 'InterContinental (PB) 3 Limited (n)\\n'\n",
      " 'Intercontinental D.C. Operating Corp. (k)\\n'\n",
      " 'Inter-Continental Florida Partner Corp. (k)\\n'\n",
      " 'InterContinental Gestion Hotelera SLU (by)\\n'\n",
      " 'Intercontinental Hospitality Corporation (k)\\n'\n",
      " 'InterContinental Hotel Berlin GmbH (au)\\n'\n",
      " 'Inter-Continental Hoteleira Limitada (aw)\\n'\n",
      " 'Inter-Continental Hotels (Montreal) Operating \\n'\n",
      " 'Corp. (ax)\\n'\n",
      " 'Inter-Continental Hotels (Montreal) Owning \\n'\n",
      " 'Corp. (ax)\\n'\n",
      " 'InterContinental Hotels (Puerto Rico) Inc. (az)\\n'\n",
      " 'Inter-Continental Hotels Corporation (k)\\n'\n",
      " 'Intercontinental Hotels Corporation de Venezuela \\n'\n",
      " 'C.A. (ba)\\n'\n",
      " 'Intercontinental Hotels Corporation Limited (b) (m)\\n'\n",
      " 'InterContinental Hotels Group (Asia Pacific) \\n'\n",
      " 'Pte Ltd. (ai)\\n'\n",
      " 'InterContinental Hotels Group (Australia) Pty \\n'\n",
      " 'Limited (aa)\\n'\n",
      " 'InterContinental Hotels Group (Canada), Inc. (o)\\n'\n",
      " 'InterContinental Hotels Group (España) SAU (by)\\n'\n",
      " 'InterContinental Hotels Group (Greater China) \\n'\n",
      " 'Limited (ac)\\n'\n",
      " 'InterContinental Hotels Group (India) Private \\n'\n",
      " 'Limited (aq)\\n'\n",
      " 'InterContinental Hotels Group (Japan), Inc. (k)\\n'\n",
      " 'InterContinental Hotels Group (New Zealand) \\n'\n",
      " 'Limited (an)\\n'\n",
      " 'InterContinental Hotels Group (Shanghai) Ltd. (bb)\\n'\n",
      " 'InterContinental Hotels Group (Vietnam) Company \\n'\n",
      " 'Limited (q)\\n'\n",
      " 'InterContinental Hotels Group Customer Services \\n'\n",
      " 'Limited (n)\\n'\n",
      " 'InterContinental Hotels Group do Brasil Limitada (bc)\\n'\n",
      " 'InterContinental Hotels Group Healthcare Trustee \\n'\n",
      " 'Limited (n)\\n'\n",
      " 'InterContinental Hotels Group Operating Corp. (e) (k)\\n'\n",
      " 'InterContinental Hotels Group Resources, LLC (b) (k)\\n'\n",
      " 'InterContinental Hotels Group Services Company (n)\\n'\n",
      " 'InterContinental Hotels Italia, S.r.L. (be)\\n'\n",
      " 'InterContinental Hotels Limited (a) (n)\\n'\n",
      " 'InterContinental Hotels Managementgesellschaft \\n'\n",
      " 'mbH (bf)\\n'\n",
      " 'InterContinental Hotels Management Montenegro \\n'\n",
      " 'd.o.o. (ce)\\n'\n",
      " 'InterContinental Hotels Nevada Corporation (k)\\n'\n",
      " 'InterContinental Hotels of San Francisco, Inc. (k)\\n'\n",
      " 'Intercontinental IOHC (Mauritius) Limited (bg)\\n'\n",
      " 'InterContinental Management AM, LLC (cm)\\n'\n",
      " 'InterContinental Management Bulgaria EOOD (bp)\\n'\n",
      " 'InterContinental Management France SAS (x)\\n'\n",
      " 'InterContinental Management Poland sp. Z.o.o (cn)\\n'\n",
      " 'InterContinental Overseas Holdings, LLC (k)\\n'\n",
      " 'KG Benefits, LLC (k)\\n'\n",
      " 'KG Gift Card Inc. (k)\\n'\n",
      " 'KG Liability LLC (k)\\n'\n",
      " 'KG Technology, LLC (k)\\n'\n",
      " 'KHRG 851 LLC (k)\\n'\n",
      " 'KHRG Aertson LLC (k)\\n'\n",
      " 'KHRG Allegro, LLC (k)\\n'\n",
      " 'KHRG Argyle, LLC (k)\\n'\n",
      " 'KHRG Atlanta Midtown LLC (k)\\n'\n",
      " 'KHRG Austin Beverage Company, LLC (k)\\n'\n",
      " 'KHRG Baltimore, LLC (k)\\n'\n",
      " 'KHRG Born LLC (k)\\n'\n",
      " 'KHRG Boston Hotel, LLC (k)\\n'\n",
      " 'KHRG Bozeman LLC (k)\\n'\n",
      " 'KHRG Buckhead LLC (k)\\n'\n",
      " 'KHRG Canary LLC (k)\\n'\n",
      " 'KHRG Cayman LLC (k)\\n'\n",
      " 'KHRG Cayman Employer Ltd. (cl)\\n'\n",
      " 'KHRG Charlottesville LLC (k)\\n'\n",
      " 'KHRG Dallas LLC (k)\\n'\n",
      " 'KHRG Dallas Beverage Company, LLC (k)\\n'\n",
      " 'KHRG Employer, LLC (k)\\n'\n",
      " 'SS Aetna Acquisition, LLC fka KHRG Goleta, LLC (k)\\n'\n",
      " 'KHRG Gray LLC (k)\\n'\n",
      " 'KHRG Gray U2 LLC (k)\\n'\n",
      " 'KHRG Huntington Beach LLC (k)\\n'\n",
      " 'KHRG Key West LLC (k)\\n'\n",
      " 'KHRG King Street, LLC (k)\\n'\n",
      " 'KHRG La Peer LLC (k)\\n'\n",
      " 'KHRG Miami Beach LLC (k)\\n'\n",
      " 'KHRG Muse LLC (k)\\n'\n",
      " 'KHRG New Orleans LLC (k)\\n'\n",
      " 'KHRG NPC LLC (k)\\n'\n",
      " 'KHRG Palladian LLC (k)\\n'\n",
      " 'KHRG Palomar Phoenix LLC (k)\\n'\n",
      " 'KHRG Philly Monaco LLC (k)\\n'\n",
      " 'KHRG Pittsburgh LLC (k)\\n'\n",
      " 'KHRG Porsche Drive LLC (k)\\n'\n",
      " 'KHRG Reynolds LLC (k)\\n'\n",
      " 'Group Financial Statements\\n'\n",
      " '214\\n'\n",
      " 'IHG\\u2002 |\\u2002 Annual Report and Form 20-F 2023')\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:27:49.619635Z",
     "start_time": "2025-07-04T10:27:49.467918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50,separators=[\"\\n\\n\", \"\\n\" , \".\", \"?\",\",\",\" \"])\n",
    "texts=text_splitter.split_documents(docs)"
   ],
   "id": "cc00655bc110aab2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:28:04.880116Z",
     "start_time": "2025-07-04T10:27:49.640941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "id": "9289707143e77ba2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.105096Z",
     "start_time": "2025-07-04T10:28:04.904057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract raw text from Document objects\n",
    "text_chunks = [doc.page_content for doc in texts]\n",
    "\n",
    "# Embed only the text content\n",
    "embeddings = embeddings.embed_documents(text_chunks)\n",
    "\n",
    "print(f\"✅ Number of embeddings: {len(embeddings)}\")\n",
    "print(f\"✅ Shape of first embedding: {len(embeddings[0])}\")\n"
   ],
   "id": "71344cd6f4a4c414",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m text_chunks = [doc.page_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m texts]\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Embed only the text content\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m embeddings = \u001B[43membeddings\u001B[49m\u001B[43m.\u001B[49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_chunks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m✅ Number of embeddings: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(embeddings)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m✅ Shape of first embedding: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(embeddings[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:150\u001B[39m, in \u001B[36mHuggingFaceEmbeddings.embed_documents\u001B[39m\u001B[34m(self, texts)\u001B[39m\n\u001B[32m    141\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34membed_documents\u001B[39m(\u001B[38;5;28mself\u001B[39m, texts: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]) -> \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[32m    142\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001B[39;00m\n\u001B[32m    143\u001B[39m \n\u001B[32m    144\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    148\u001B[39m \u001B[33;03m        List of embeddings, one for each text.\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_embed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencode_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:127\u001B[39m, in \u001B[36mHuggingFaceEmbeddings._embed\u001B[39m\u001B[34m(self, texts, encode_kwargs)\u001B[39m\n\u001B[32m    125\u001B[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m     embeddings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    129\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    130\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mencode_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[32m    131\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    133\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(embeddings, \u001B[38;5;28mlist\u001B[39m):\n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    135\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mExpected embeddings to be a Tensor or a numpy array, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    136\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mgot a list instead.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    137\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    113\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1052\u001B[39m, in \u001B[36mSentenceTransformer.encode\u001B[39m\u001B[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001B[39m\n\u001B[32m   1049\u001B[39m features.update(extra_features)\n\u001B[32m   1051\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m-> \u001B[39m\u001B[32m1052\u001B[39m     out_features = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1053\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.device.type == \u001B[33m\"\u001B[39m\u001B[33mhpu\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1054\u001B[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1133\u001B[39m, in \u001B[36mSentenceTransformer.forward\u001B[39m\u001B[34m(self, input, **kwargs)\u001B[39m\n\u001B[32m   1127\u001B[39m             module_kwarg_keys = \u001B[38;5;28mself\u001B[39m.module_kwargs.get(module_name, [])\n\u001B[32m   1128\u001B[39m         module_kwargs = {\n\u001B[32m   1129\u001B[39m             key: value\n\u001B[32m   1130\u001B[39m             \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m kwargs.items()\n\u001B[32m   1131\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m module_kwarg_keys \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28mhasattr\u001B[39m(module, \u001B[33m\"\u001B[39m\u001B[33mforward_kwargs\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m module.forward_kwargs)\n\u001B[32m   1132\u001B[39m         }\n\u001B[32m-> \u001B[39m\u001B[32m1133\u001B[39m     \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodule_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1134\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:437\u001B[39m, in \u001B[36mTransformer.forward\u001B[39m\u001B[34m(self, features, **kwargs)\u001B[39m\n\u001B[32m    430\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001B[39;00m\n\u001B[32m    431\u001B[39m trans_features = {\n\u001B[32m    432\u001B[39m     key: value\n\u001B[32m    433\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m features.items()\n\u001B[32m    434\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mattention_mask\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mtoken_type_ids\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33minputs_embeds\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    435\u001B[39m }\n\u001B[32m--> \u001B[39m\u001B[32m437\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mauto_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtrans_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    438\u001B[39m token_embeddings = outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    439\u001B[39m features[\u001B[33m\"\u001B[39m\u001B[33mtoken_embeddings\u001B[39m\u001B[33m\"\u001B[39m] = token_embeddings\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:482\u001B[39m, in \u001B[36mMPNetModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[39m\n\u001B[32m    480\u001B[39m head_mask = \u001B[38;5;28mself\u001B[39m.get_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m.config.num_hidden_layers)\n\u001B[32m    481\u001B[39m embedding_output = \u001B[38;5;28mself\u001B[39m.embeddings(input_ids=input_ids, position_ids=position_ids, inputs_embeds=inputs_embeds)\n\u001B[32m--> \u001B[39m\u001B[32m482\u001B[39m encoder_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    486\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    487\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    490\u001B[39m sequence_output = encoder_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    491\u001B[39m pooled_output = \u001B[38;5;28mself\u001B[39m.pooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:334\u001B[39m, in \u001B[36mMPNetEncoder.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[39m\n\u001B[32m    331\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states:\n\u001B[32m    332\u001B[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001B[32m--> \u001B[39m\u001B[32m334\u001B[39m layer_outputs = \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    335\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    337\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    338\u001B[39m \u001B[43m    \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    339\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    340\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    342\u001B[39m hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    344\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:303\u001B[39m, in \u001B[36mMPNetLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001B[39m\n\u001B[32m    300\u001B[39m attention_output = self_attention_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    301\u001B[39m outputs = self_attention_outputs[\u001B[32m1\u001B[39m:]  \u001B[38;5;66;03m# add self attentions if we output attention weights\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m303\u001B[39m intermediate_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mintermediate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    304\u001B[39m layer_output = \u001B[38;5;28mself\u001B[39m.output(intermediate_output, attention_output)\n\u001B[32m    305\u001B[39m outputs = (layer_output,) + outputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:257\u001B[39m, in \u001B[36mMPNetIntermediate.forward\u001B[39m\u001B[34m(self, hidden_states)\u001B[39m\n\u001B[32m    256\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m257\u001B[39m     hidden_states = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    258\u001B[39m     hidden_states = \u001B[38;5;28mself\u001B[39m.intermediate_act_fn(hidden_states)\n\u001B[32m    259\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:44.484801Z",
     "start_time": "2025-07-04T10:47:44.318731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "docs = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadatas)]"
   ],
   "id": "a82f171d5244f15e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadatas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mschema\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Document\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m docs = [Document(page_content=text, metadata=meta) \u001B[38;5;28;01mfor\u001B[39;00m text, meta \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(texts, \u001B[43mmetadatas\u001B[49m)]\n",
      "\u001B[31mNameError\u001B[39m: name 'metadatas' is not defined"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.243679400Z",
     "start_time": "2025-07-04T09:38:25.891988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import os, time\n",
    "\n",
    "# Load credentials securely\n",
    "KEY = os.getenv('ZILLIZ_API_KEY')\n",
    "URL = os.getenv('ZILLIZ_URI')\n",
    "\n",
    "# Ensure your credentials are loaded\n",
    "assert KEY is not None, \"ZILLIZ_API_KEY not set\"\n",
    "assert URL is not None, \"ZILLIZ_URI not set\"\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Index configurations\n",
    "index_types = {\n",
    "    \"flat\": {\"index_type\": \"flat\", \"metric_type\": \"L2\"},\n",
    "    \"hnsw\": {\"index_type\": \"hnsw\", \"metric_type\": \"L2\", \"params\": {\"M\": 16, \"efConstruction\": 200}},\n",
    "    \"ivf\": {\"index_type\": \"ivf_flat\", \"metric_type\": \"L2\", \"params\": {\"nlist\": 100}},\n",
    "}\n",
    "\n",
    "# Loop through each index type and store vectors\n",
    "for name, index_param in index_types.items():\n",
    "    print(f\"🚀 Creating collection: rag_{name}\")\n",
    "    start = time.time()\n",
    "\n",
    "    vector_store = Milvus.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embedding_model,\n",
    "        connection_args={\"uri\": URL, \"token\": KEY},\n",
    "        collection_name=f\"rag1_{name}\",\n",
    "        index_params=index_param\n",
    "    )\n",
    "\n",
    "    print(f\"✅ Index '{name}' created in {time.time() - start:.2f} seconds\\n\")\n"
   ],
   "id": "51c9bdada93ecd2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Creating collection: rag_flat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 15:09:17,388 [ERROR][handler]: RPC error: [create_index], <MilvusException: (code=1100, message=invalid parameter[expected=valid index][actual=invalid index type: flat])>, <Time:{'RPC start': '2025-07-04 15:09:17.079699', 'RPC error': '2025-07-04 15:09:17.388274'}> (decorators.py:140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Index 'flat' created in 55.76 seconds\n",
      "\n",
      "🚀 Creating collection: rag_hnsw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 15:10:15,312 [ERROR][handler]: RPC error: [create_index], <MilvusException: (code=1100, message=invalid parameter[expected=valid index][actual=invalid index type: hnsw])>, <Time:{'RPC start': '2025-07-04 15:10:15.038201', 'RPC error': '2025-07-04 15:10:15.312383'}> (decorators.py:140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Index 'hnsw' created in 58.04 seconds\n",
      "\n",
      "🚀 Creating collection: rag_ivf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 15:11:21,088 [ERROR][handler]: RPC error: [create_index], <MilvusException: (code=1100, message=invalid parameter[expected=valid index][actual=invalid index type: ivf_flat])>, <Time:{'RPC start': '2025-07-04 15:11:20.781385', 'RPC error': '2025-07-04 15:11:21.088607'}> (decorators.py:140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Index 'ivf' created in 64.53 seconds\n",
      "\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.243679400Z",
     "start_time": "2025-07-04T09:42:45.620968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collection_map = {\n",
    "    \"flat\": \"rag1_flat\",\n",
    "    \"hnsw\": \"rag1_hnsw\",\n",
    "    \"ivf\": \"rag1_ivf\"\n",
    "}\n"
   ],
   "id": "714a5b4ba1829a6d",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.243679400Z",
     "start_time": "2025-07-04T09:56:21.573311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_with_timing(index_name: str, query: str, k: int = 5):\n",
    "    vs = Milvus(\n",
    "        embedding_function=embedding_model,\n",
    "        connection_args={\"uri\": URL, \"token\": KEY},\n",
    "        collection_name=collection_map[index_name]\n",
    "    )\n",
    "\n",
    "    retriever = vs.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    start = time.time()\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    return results, duration\n"
   ],
   "id": "4d33241e4fa2bab2",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.274821500Z",
     "start_time": "2025-07-04T09:58:57.378946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What are Key performance measures and non-GAAP measures\"\n",
    "\n",
    "retrieval_logs = {}\n",
    "\n",
    "for index in collection_map:\n",
    "    results, duration = retrieve_with_timing(index, query)\n",
    "    retrieval_logs[index] = {\n",
    "        \"results\": results,\n",
    "        \"time\": duration\n",
    "    }\n"
   ],
   "id": "652156eaf0cef2e9",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.274821500Z",
     "start_time": "2025-07-04T09:58:54.253705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, log in retrieval_logs.items():\n",
    "    print(f\"📊 {index.upper()} — Time: {log['time']:.4f}s\")\n",
    "    print(\"🔹 Top Result Preview:\", log[\"results\"][0].page_content[:200], \"\\n\")\n"
   ],
   "id": "a1a264d44373358b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 FLAT — Time: 0.2771s\n",
      "🔹 Top Result Preview: (described as Non-GAAP) are presented that are used internally by management as key measures to assess performance. Non-GAAP measures are either not defined under \n",
      "IFRS or are adjusted IFRS figures. F \n",
      "\n",
      "📊 HNSW — Time: 0.3079s\n",
      "🔹 Top Result Preview: (described as Non-GAAP) are presented that are used internally by management as key measures to assess performance. Non-GAAP measures are either not defined under \n",
      "IFRS or are adjusted IFRS figures. F \n",
      "\n",
      "📊 IVF — Time: 0.4123s\n",
      "🔹 Top Result Preview: (described as Non-GAAP) are presented that are used internally by management as key measures to assess performance. Non-GAAP measures are either not defined under \n",
      "IFRS or are adjusted IFRS figures. F \n",
      "\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.281809700Z",
     "start_time": "2025-07-04T09:58:50.164726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def precision_at_k(results, expected_keywords, k=5):\n",
    "    hits = 0\n",
    "    for doc in results[:k]:\n",
    "        content = doc.page_content.lower()\n",
    "        if any(keyword.lower() in content for keyword in expected_keywords):\n",
    "            hits += 1\n",
    "    return hits / k\n"
   ],
   "id": "de6aa206bcda821",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.284374600Z",
     "start_time": "2025-07-04T10:00:05.864245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define what you expect in a correct answer\n",
    "expected_keywords = [\"Non-GAAP\",\"measures\",\"performance\",\"figures\"]\n",
    "\n",
    "# Store precision scores\n",
    "for index, log in retrieval_logs.items():\n",
    "    precision = precision_at_k(log[\"results\"], expected_keywords, k=10)\n",
    "    retrieval_logs[index][\"precision@5\"] = precision\n",
    "    print(f\"🎯 {index.upper()} — Precision@5: {precision:.2f} — Time: {log['time']:.4f}s\")\n"
   ],
   "id": "1a1bf4b3e1d1db21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 FLAT — Precision@5: 0.50 — Time: 0.3103s\n",
      "🎯 HNSW — Precision@5: 0.50 — Time: 0.2894s\n",
      "🎯 IVF — Precision@5: 0.50 — Time: 0.3152s\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.289562300Z",
     "start_time": "2025-07-04T10:27:41.520297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "indexes = list(retrieval_logs.keys())\n",
    "times = [retrieval_logs[idx][\"time\"] for idx in indexes]\n",
    "precisions = [retrieval_logs[idx][\"precision@5\"] for idx in indexes]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(indexes, precisions, alpha=0.6, label=\"Precision@5\", color=\"green\")\n",
    "plt.plot(indexes, times, marker='o', label=\"Retrieval Time (s)\", color=\"blue\")\n",
    "plt.legend()\n",
    "plt.title(\"Precision@5 vs Retrieval Time\")\n",
    "plt.ylabel(\"Score / Time (s)\")\n",
    "plt.xlabel(\"Index Type\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "c64adbf82c9a3e7",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieval_logs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m indexes = \u001B[38;5;28mlist\u001B[39m(\u001B[43mretrieval_logs\u001B[49m.keys())\n\u001B[32m      4\u001B[39m times = [retrieval_logs[idx][\u001B[33m\"\u001B[39m\u001B[33mtime\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indexes]\n\u001B[32m      5\u001B[39m precisions = [retrieval_logs[idx][\u001B[33m\"\u001B[39m\u001B[33mprecision@5\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indexes]\n",
      "\u001B[31mNameError\u001B[39m: name 'retrieval_logs' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.294851Z",
     "start_time": "2025-07-04T10:02:47.344465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_with_mmr(index_name: str, query: str, k: int = 5, fetch_k: int = 20, lambda_mult: float = 0.5):\n",
    "    print(f\"\\n🔁 MMR Re-ranking in: {index_name.upper()}\")\n",
    "\n",
    "    vs = Milvus(\n",
    "        embedding_function=embedding_model,\n",
    "        connection_args={\"uri\": URL, \"token\": KEY},\n",
    "        collection_name=collection_map[index_name]\n",
    "    )\n",
    "\n",
    "    retriever = vs.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": k,\n",
    "            \"fetch_k\": fetch_k,        # Number of initial candidates\n",
    "            \"lambda_mult\": lambda_mult # Balance: 0.0 = max diversity, 1.0 = max relevance\n",
    "        }\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    print(f\"⏱️ MMR Retrieval Time: {duration:.4f} seconds\")\n",
    "    print(\"📄 MMR Top Result Preview:\\n\", results[0].page_content[:300], \"\\n\")\n",
    "\n",
    "    return results, duration\n"
   ],
   "id": "a70179e9a1fb1235",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.296581Z",
     "start_time": "2025-07-04T10:03:19.222550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What are Key performance measures and non-GAAP measures\"\n",
    "\n",
    "mmr_logs = {}\n",
    "\n",
    "for index in collection_map:\n",
    "    results, duration = retrieve_with_mmr(index, query)\n",
    "    mmr_logs[index] = {\n",
    "        \"results\": results,\n",
    "        \"time\": duration\n",
    "    }\n"
   ],
   "id": "9b6200317a27d383",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 MMR Re-ranking in: FLAT\n",
      "⏱️ MMR Retrieval Time: 0.7518 seconds\n",
      "📄 MMR Top Result Preview:\n",
      " (described as Non-GAAP) are presented that are used internally by management as key measures to assess performance. Non-GAAP measures are either not defined under \n",
      "IFRS or are adjusted IFRS figures. Further explanation in relation to these measures can be found on page 84 to 88 and reconciliations t \n",
      "\n",
      "\n",
      "🔁 MMR Re-ranking in: HNSW\n",
      "⏱️ MMR Retrieval Time: 0.9001 seconds\n",
      "📄 MMR Top Result Preview:\n",
      " (described as Non-GAAP) are presented that are used internally by management as key measures to assess performance. Non-GAAP measures are either not defined under \n",
      "IFRS or are adjusted IFRS figures. Further explanation in relation to these measures can be found on page 84 to 88 and reconciliations t \n",
      "\n",
      "\n",
      "🔁 MMR Re-ranking in: IVF\n",
      "⏱️ MMR Retrieval Time: 1.1073 seconds\n",
      "📄 MMR Top Result Preview:\n",
      " (described as Non-GAAP) are presented that are used internally by management as key measures to assess performance. Non-GAAP measures are either not defined under \n",
      "IFRS or are adjusted IFRS figures. Further explanation in relation to these measures can be found on page 84 to 88 and reconciliations t \n",
      "\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.298730500Z",
     "start_time": "2025-07-04T10:03:56.803991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "expected_keywords = [\"Non-GAAP\",\"measures\",\"performance\",\"figures\"]\n",
    "\n",
    "for index, log in mmr_logs.items():\n",
    "    precision = precision_at_k(log[\"results\"], expected_keywords)\n",
    "    mmr_logs[index][\"precision@5\"] = precision\n",
    "    print(f\"🔁 MMR {index.upper()} — Precision@5: {precision:.2f} — Time: {log['time']:.4f}s\")\n"
   ],
   "id": "162d9b350dcd060",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 MMR FLAT — Precision@5: 1.00 — Time: 0.7518s\n",
      "🔁 MMR HNSW — Precision@5: 1.00 — Time: 0.9001s\n",
      "🔁 MMR IVF — Precision@5: 1.00 — Time: 1.1073s\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.298730500Z",
     "start_time": "2025-07-04T10:27:35.812959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"📊 MMR vs Default Precision@5\\n\")\n",
    "for index in collection_map:\n",
    "    original = retrieval_logs[index][\"precision@5\"]\n",
    "    reranked = mmr_logs[index][\"precision@5\"]\n",
    "    print(f\"{index.upper()} — Base: {original:.2f}, MMR: {reranked:.2f}\")\n",
    "\n"
   ],
   "id": "4756cd7f2d48689b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 MMR vs Default Precision@5\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'collection_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m📊 MMR vs Default Precision@5\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[43mcollection_map\u001B[49m:\n\u001B[32m      3\u001B[39m     original = retrieval_logs[index][\u001B[33m\"\u001B[39m\u001B[33mprecision@5\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m      4\u001B[39m     reranked = mmr_logs[index][\u001B[33m\"\u001B[39m\u001B[33mprecision@5\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[31mNameError\u001B[39m: name 'collection_map' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.300150400Z",
     "start_time": "2025-07-04T10:07:21.857565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant. Use the context below to answer the question.\n",
    "If the context does not contain enough information, say so clearly.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    ")\n"
   ],
   "id": "b229971167714e87",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.300150400Z",
     "start_time": "2025-07-04T10:27:25.690140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\n",
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n"
   ],
   "id": "8b20dc3a326f59dc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T10:47:42.300150400Z",
     "start_time": "2025-07-04T10:27:27.558353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is the benefit of using HNSW for similarity search?\"\n",
    "context_docs = mmr_logs[\"hnsw\"][\"results\"]\n",
    "\n",
    "# Combine context\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in context_docs])\n",
    "\n",
    "# Run Gemini through LLMChain\n",
    "response = qa_chain.run({\n",
    "    \"context\": context,\n",
    "    \"question\": query\n",
    "})\n",
    "\n",
    "print(\"🧠 Gemini Answer:\\n\", response)\n"
   ],
   "id": "f82d8421debf2502",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmr_logs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m query = \u001B[33m\"\u001B[39m\u001B[33mWhat is the benefit of using HNSW for similarity search?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m context_docs = \u001B[43mmmr_logs\u001B[49m[\u001B[33m\"\u001B[39m\u001B[33mhnsw\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mresults\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Combine context\u001B[39;00m\n\u001B[32m      5\u001B[39m context = \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.join([doc.page_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m context_docs])\n",
      "\u001B[31mNameError\u001B[39m: name 'mmr_logs' is not defined"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
